Computer Science for All

by Christoph Kirsch

This is a proposal for a book on the absolute basics of computer science. The idea is to introduce the field in such a way that the material is accessible to broad audiences. We envision the target audience to be anyone using information technology every day without understanding how it works but with sufficient motivation to find out. The book will empower its readers to turn their smart phones, tablets, and laptops into what they are supposed to be: the most fascinating and powerful tools ever created rather than the seemingly unavoidable nightmare of so many people, amateurs and professionals alike.

We should emphasize that the book is not about how to use any particular device such as a smart phone or an office app such as Word or Excel. There are plenty of books about that. The goal here is much more ambitious than that and its readers will be challenged accordingly. The idea is to explain the absolute basics of computer science in order to develop a fundamental understanding of what software is and how it works in general on any hardware, ultimately enabling readers to make informed decisions involving computers and solve whatever computer problem comes along. The key challenge in doing so is to have readers understand that everything can in principle be automated by a computer but only by breaking down the solution of a problem into the tiniest steps that a mindless machine can follow. Laying out even the most obvious parts of a solution is in fact what computer scientists do. Seeing that will make readers sharpen their mind considerably and even change the way they think.

Readers should be at least 14 years old and planning to obtain or already holding at least a high school degree. The only prerequisite will be an understanding of elementary arithmetic (addition, subtraction, multiplication, and division of whole numbers) and Boolean logic (logical AND, OR, and NEGATION of true and false statements). Both topics will anyway be revisited in the book.

1. Information

The book begins with a bit of groundwork emphasizing the fact that everything happening on a digital device is encoded in bits, and nothing else. The only reason why these machines are so powerful and in fact computationally universal is the enormous amount of bits they can store and the speed and energy efficiency at which they can manipulate these bits. This insight is key to understanding information technology and therefore emphasized throughout the book. We begin with examples of how every day information such as numbers, characters, text, images, and video is all encoded in just bits. We also show how those bits are later decoded back to their original form making them accessible to humans again.

2. The Machine

The next topic is a simple yet representative machine model of virtually any digital device available today. The model is in fact a subset of an existing, fully realistic machine that we developed during the course of teaching undergraduate students for two decades. The goal is to enable even casual readers to develop an intuition on how computers work on the level of bits, which is surprisingly simple to do. Most of the complexity of modern digital devices is due to performance optimizations which we deliberately leave out to keep things accessible. Instead we focus on developing an early intuition on what code and data is, what the difference is, and the fact that both are anyway encoded in just bits. This chapter also includes a simple model of digital memory and exposes the reader to fundamental properties that have direct counterparts in the real world, as it is often the case with computer science, such as the decision of whether to throw away something (forget) or keeping it (memorize).

3. Programming

With the machine model in mind, readers will appreciate the fact that developing software directly on the machine is possible but too cumbersome and errorprone. It is therefore time to introduce the notion of high-level programming languages and, after that, the notion of software development tools that enable building the most complex systems ever created by humans. Similar to the machine model, we introduce a simple yet representative programming language which is, again, a subset of an existing, in fact still widely used programming language called C. The language we use has also been developed during years of teaching. The idea of this chapter is to show how simple programs written in that language are actually run on a computer using the previously introduced machine model. Here there are plenty of opportunities to point out fundamental questions such as how long and how much memory and energy it takes to solve a problem and whether a problem can be solved at all. The latter, for example, explains why computers sometime become unresponsive for unpredictable amounts of time driving their users mad.

4. Tools

Even the most convenient high-level programming languages are by far not enough to enable developers build the systems we see today. Like all engineers they need tools to do it. Software development tools as a topic is interesting because their design explains a lot about what software is. In fact, the tools define what a program written in a programming language actually means. This is usually done through language translation. Thus exposing the readers to the design of the tools is key to showing how meaning is given to code, at least in principle. There are fascinating analogies in the real world such as the self-referential paradox that an English dictionary defines the meaning of English using English. The same is true with software development tools. They are usually written in the programming language to which they give meaning. The difference to English though is that there is no paradox here. Showing how that works is our goal. Readers will then start asking questions about computers they would have never been able to ask before. We envision the outcome to be new insights into what is possible and what is not, enabling readers to develop more confidence when it comes to assessing new technology such as artifical intelligence and self-driving cars.

5. Virtualization

One of the key breakthroughs of recent years is that computation has become a utility just like electricity and water. Cloud computing and, in the near future, edge computing creates enormous potential, just like the reliable availability of power and water. The key enabling technology is virtualization which is a concept whose understanding is elusive even to many computer science students. However, we believe we have found a way to teach virtualization even to broad audiences based on a combination of our machine model, programming language, and tool set. The idea is to demonstrate how software can create the illusion of any machine, in particular the one it runs on, very efficiently. This is another form of self-referentialy that is fundamental in computer science. Seeing that enables our readers to grasp the full extent of the universality of digital computing.

Code Examples

We propose to use code examples from our educational software system called selfie which we have developed for about five years. Selfie is software that constructs its own meaning in three distinct, self-referential ways related to the above machine model, programming language, tools, and virtualization: http://selfie.cs.uni-salzburg.at

About the author

Christoph Kirsch is Professor of Computer Science at the University of Salzburg, Austria. He has been teaching undergraduate and graduate classes for two decades, in Salzburg as well as at the University of California at Berkeley, as Postdoctoral Scholar and Visiting Professor. The book is the result of years of experience in how to simplify and present computer science content to the extent that virtually everyone sufficiently motivated can finally appreciate and understand how digital devices actually work, what they are capable of, and what their limitations are.